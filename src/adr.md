# Architecture Decision Record: Выбор архитектурных решений

1: Принятие микросервисной архитектуры для системы диагностики

 

Контекст: Требуется построить сложную систему с независимо масштабируемыми компонентами (ИИ-помощник, диагностика, интеграция с каталогами, сообщество), обеспечивая высокую доступность (≥99%) и обработку до 5000 одновременных сессий. Система должна развиваться итеративно.

Варианты:
- Монолитное приложение
- Микросервисная архитектура
- Модульный монолит (Modulith)

Выбор: Микросервисная архитектура

Обоснование:
- Неравномерная нагрузка: ИИ-сервис и модуль диагностики требуют больше ресурсов, чем статические сервисы
- Независимое развертывание: необходимо часто обновлять модели ИИ и базу знаний без перезапуска всей системы
- Разнородность технологий: ИИ на Python, веб-сервисы на Node.js/Java, что естественно ложится на разные сервисы
- Отказоустойчивость: сбой в одном сервисе не должен приводить к остановке всей системы

Последствия:
- Положительные: независимое масштабирование, гибкость выбора технологий для каждого сервиса, легкость замены компонентов
- Отрицательные: сложность оркестрации, распределенные транзакции, повышенные требования к мониторингу и DevOps

---

2: Выбор языков и фреймворков для бэкенд-сервисов

 

Контекст: Необходимо реализовать разнородные сервисы: высоконагруженные API, ИИ-обработка, асинхронные задачи. Команда имеет опыт с Python и Node.js.

Варианты:
- Единый стек (например, только Java Spring Boot)
- Специализированные языки под задачи
- Смешанный стек на основе экспертизы команды

Выбор: Смешанный стек:
- Python (FastAPI): для ИИ-сервисов, ML-пайплайнов, обработки данных
- Node.js (NestJS): для API Gateway, сервисов аутентификации, real-time коммуникаций
- Go: для высоконагруженных сервисов интеграции с каталогами и обработки платежей

Обоснование:
- Python: лучшая экосистема для ML (TensorFlow, PyTorch, scikit-learn)
- Node.js: асинхронная природа подходит для I/O-bound операций, единый язык с фронтендом
- Go: высокая производительность и низкое потребление памяти для CPU-intensive задач
- Соответствие экспертизе команды снижает риски разработки

Последствия:
- Положительные: использование оптимальных инструментов для каждой задачи, высокая производительность
- Отрицательные: необходимость мультиязыковой поддержки в CI/CD, сложность переиспользования кода между сервисами

---

3: Выбор фронтенд-стэка для кроссплатформенного приложения

 

Контекст: Требуется единая кодовая база для веб-приложения и мобильных приложений (iOS/Android) с адаптивным интерфейсом, работающим на экранах от 320px до 4K.

Варианты:
- Раздельная разработка: нативный iOS/Swift, нативный Android/Kotlin, веб/React
- Гибридные фреймворки: React Native, Flutter, Ionic
- Прогрессивное веб-приложение (PWA) + Capacitor

Выбор: React для веба + React Native для мобильных приложений

Обоснование:
- Единая ментальная модель для разработчиков (React на всех платформах)
- Возможность переиспользования бизнес-логики и компонентов (~70% кода)
- Зрелая экосистема React Native с поддержкой нативных модулей для работы с камерой (для сканирования штрих-кодов)
- TypeScript для типизации и снижения количества runtime-ошибок
- Широкая распространенность на рынке, легко найти разработчиков

Последствия:
- Положительные: экономия на разработке и поддержке, единый стейт-менеджмент (Redux Toolkit/MobX), горячая перезагрузка
- Отрицательные: производительность ниже нативной для сложных анимаций, зависимость от моста в React Native, размер бандла

---

4: Выбор стэка для ИИ-помощника и NLP-обработки

 

Контекст: Требуется ИИ-помощник, понимающий технические термины электроники, с точностью диагностики ≥80% для топ-1000 моделей. Обработка должна быть ≤3 секунд.

Варианты:
- Использование готовых NLP API (OpenAI GPT, Google Dialogflow)
- Fine-tuning открытых моделей (BERT, GPT-2)
- Обучение собственной модели с нуля
- Гибридный подход: rule-based система + ML

Выбор: Гибридный подход:
- Fine-tuned BERT-модель для классификации интентов и извлечения сущностей
- Rule-based диалоговый движок для гарантированной работы сценариев безопасности
- Векторные эмбеддинги для поиска похожих случаев
- Внешний LLM API (GPT-4) для обработки edge-cases и генерации объяснений

Обоснование:
- BERT fine-tuning дает высокую точность на технической лексике при ограниченных данных
- Rule-based компонент гарантирует обязательные предупреждения о безопасности (требование ТБ-006)
- Векторный поиск ускоряет диагностику на основе исторических данных
- GPT-4 как fallback для нестандартных запросов улучшает пользовательский опыт
- Локальные модели обеспечивают отклик ≤3с без зависимости от внешних API

Последствия:
- Положительные: баланс точности и контроля, соответствие требованиям безопасности, работа offline-режиме
- Отрицательные: сложность поддержки нескольких моделей, необходимость регулярного переобучения на новых данных

---

5: Выбор API Gateway и коммуникационных паттернов

 

Контекст: Множество клиентов (веб, мобильные приложения) обращаются к десяткам микросервисов. Необходимы: аутентификация, rate limiting, кэширование, маршрутизация.

Варианты:
- Собственная реализация на основе nginx + Lua
- Готовые API Gateway: Kong, Tyk, AWS API Gateway
- Service mesh подход: Istio + Envoy
- GraphQL Gateway (Apollo Federation)

Выбор: Kong в качестве API Gateway + GraphQL Apollo Federation для агрегации данных

Обоснование:
- Kong: открытый исходный код, плагины для OAuth 2.0, rate limiting, мониторинг, легкая интеграция с Kafka
- Apollo Federation: единый GraphQL endpoint для клиентов, позволяет агрегировать данные из нескольких сервисов за один запрос (например, данные устройства + история ремонтов + доступные компоненты)
- Разделение ответственности: Kong для инфраструктурных задач (безопасность, трафик), Apollo для бизнес-агрегации
- Поддержка как REST (для интеграций), так и GraphQL (для фронтенда)

Последствия:
- Положительные: декларативная конфигурация маршрутов, GraphQL уменьшает over-fetching данных, единая точка мониторинга трафика
- Отрицательные: дополнительная точка отказа, необходимость поддержки двух систем, сложность отладки GraphQL запросов

---

6: Выбор стратегии аутентификации и авторизации

 

Контекст: Необходима многоуровневая система доступа (Гость, Пользователь, Администратор, Эксперт) с поддержкой социальных логинов, двухфакторной аутентификации и соответствием 152-ФЗ.

Варианты:
- Кастомная реализация JWT + сессии
- Identity Provider (Keycloak, Auth0, Okta)
- OAuth 2.0 / OpenID Connect провайдеры (Google, VK, Yandex)
- Безсерверные решения (AWS Cognito, Firebase Auth)

Выбор: Keycloak как Identity Provider + JWT для сервисной авторизации

Обоснование:
- Keycloak: открытый исходный код, поддержка OIDC, SAML, социальных логинов, кастомных атрибутов пользователей
- Гибкая система ролей и политик для сложных сценариев доступа (например, "Эксперт может редактировать БЗ только в своей категории техники")
- Возможность self-hosting, что критично для хранения персональных данных в РФ
- Интеграция с Active Directory для корпоративных сценариев
- JWT уменьшает нагрузку на сервисы аутентификации, так как проверка токена может выполняться на уровне API Gateway

Последствия:
- Положительные: единая точка управления пользователями, поддержка множества протоколов, соответствие стандартам безопасности
- Отрицательные: сложность настройки и поддержки Keycloak кластера, кривая обучения для команды

---

7: Выбор стратегии хранения и обработки медиаконтента

 

Контекст: Система хранит инструкции с фото/видео, схемы устройств, пользовательские фото неисправностей. Требуется обработка (ресайзинг, водяные знаки), CDN-раздача и бэкапы.

Варианты:
- Хранение в базе данных (BLOB)
- Файловая система сервера
- Объектные хранилища (S3-совместимые)
- Специализированные медиа-сервисы (Cloudinary, imgix)

Выбор: MinIO (S3-совместимое хранилище) + собственный сервис обработки изображений

Обоснование:
- MinIO: открытый исходный код, самодостаточность (не зависит от облачных провайдеров), S3 API для простой интеграции
- Собственный сервис обработки: полный контроль над конвейером (например, автоматическое наложение предупреждающих знаков на схемы с высоким напряжением)
- Разделение origin storage и CDN: MinIO как источник истины, CDN (например, Cloudflare) для раздачи
- Поддержка версионирования объектов для отслеживания изменений инструкций
- Экономия на внешних медиа-сервисах при больших объемах

Последствия:
- Положительные: полный контроль над данными, предсказуемые расходы, независимость от вендоров
- Отрицательные: необходимость самостоятельно настраивать репликацию, мониторинг и бэкапы хранилища

---

8: Выбор инструментов мониторинга, логирования и алертинга

 

Контекст: Система состоит из 15+ микросервисов, требует мониторинга доступности ≥99%, сбора метрик производительности, centralized logging и алертинга при нарушениях SLA.

Варианты:
- Облачные managed-сервисы (Datadog, New Relic)
- Стеки на основе открытого ПО (ELK, TICK, Prometheus+Grafana)
- Гибридный подход

Выбор: Prometheus + Grafana + Loki + Tempo (Grafana стэк)

Обоснование:
- Prometheus: pull-модель сбора метрик идеально подходит для Kubernetes, мощный язык запросов PromQL
- Grafana: единая панель для метрик, логов и трассировок, богатая экосистема дашбордов
- Loki: индексирование только метаданных логов, экономичное хранение, интеграция с Grafana
- Tempo: distributed tracing для анализа производительности сквозных сценариев (например, полный путь "диагностика → рекомендация → заказ")
- Открытый исходный код, отсутствие лицензионных ограничений при росте объема данных

Последствия:
- Положительные: единый стек для observability, мощные возможности корреляции метрик и логов, активное комьюнити
- Отрицательные: необходимость самостоятельно масштабировать и поддерживать стэк, кривая обучения для сложных запросов

---

9: Выбор CI/CD и стратегии развертывания

 

Контекст: Команда из 10+ разработчиков работает над 15+ микросервисами. Необходимы автоматические тесты, контейнеризация, деплой в staging/production с минимальным downtime.

Варианты:
- Самописные скрипты на базе Jenkins
- GitLab CI/CD
- GitHub Actions
- CircleCI + ArgoCD

Выбор: GitHub Actions + ArgoCD + Kubernetes

Обоснование:
- GitHub Actions: тесная интеграция с GitHub (основной VCS), marketplace действий, бесплатные минуты для open source
- ArgoCD: GitOps подход — состояние кластера описывается в Git, автоматические деплои при изменениях
- Kubernetes: оркестрация контейнеров, автоскейлинг, self-healing, namespaces для изоляции сред
- Canary-деплой через Argo Rollouts для постепенного вкатывания изменений в ИИ-моделях
- Мульти-кластерная архитектура для географического распределения (ЕС и РФ для соблюдения 152-ФЗ)

Последствия:
- Положительные: декларативная инфраструктура, автоматические rollback при сбоях, легкое масштабирование
- Отрицательные: высокая сложность Kubernetes, необходимость глубоких знаний для troubleshooting, зависимость от стабильности Git-репозитория

---

10: Выбор стратегии тестирования и обеспечения качества

 

Контекст: Критически важна точность ИИ-диагностики (≥80%), безопасность финансовых операций, удобство интерфейса (SUS ≥75). Необходимо тестирование на всех уровнях.

Варианты:
- Ручное тестирование
- Автоматизированное тестирование с фокусом на unit-тесты
- Сквозное (E2E) тестирование всех пользовательских сценариев
- Комбинация подходов

Выбор: Комплексная стратегия Testing Pyramid + Chaos Engineering

Обоснование:
- Unit-тесты (60%): Jest для фронтенда, pytest для Python-сервисов, высокое покрытие бизнес-логики
- Интеграционные тесты (25%): тестирование взаимодействия между сервисами, работа с реальными БД в тестовом контуре
- E2E тесты (15%): Cypress для веба, Detox для мобильных приложений, проверка критичных пользовательских путей
- Нагрузочное тестирование: k6 для проверки требования 5000 одновременных сессий
- Chaos Engineering: Chaos Mesh для тестирования устойчивости к сбоям (отказ БД, сетевые задержки)
- A/B тестирование: для проверки эффективности новых алгоритмов ИИ

Последствия:
- Положительные: высокое качество кода, быстрая обратная связь при разработке, уверенность в изменениях
- Отрицательные: высокие затраты на поддержку тестовой инфраструктуры, долгое выполнение полного тестового сьюта

---

11: Выбор стратегии работы с данными и миграциями

 

Контекст: Полиглотная архитектура БД требует согласованных миграций, seed-данных (онтология техники), бэкапов и восстановления. Данные должны соответствовать 152-ФЗ.

Варианты:
- Ручные миграции
- Инструменты, специфичные для каждой БД
- Универсальный инструмент миграций
- Git-подход к данным

Выбор: Liquibase для PostgreSQL + кастомные миграции для других БД + DVC для данных ИИ-моделей

Обоснование:
- Liquibase: отслеживание миграций через Git, откат изменений, поддержка multiple databases
- Кастомные миграции для Neo4j: Cypher-скрипты под контролем версий для обновления графа знаний
- Elasticsearch: версионирование индексов через alias для zero-downtime реиндексации
- DVC (Data Version Control): контроль версий наборов данных для обучения ИИ, воспроизводимость экспериментов
- Ежедневные бэкапы: BorgBackup для дедупликации и шифрования резервных копий
- Data mesh принципы: каждый сервис отвечает за свои данные, публикует контракты через API

Последствия:
- Положительные: воспроизводимость развертывания, возможность отката миграций, контроль версий данных
- Отрицательные: сложность координации миграций между разными БД, необходимость кастомных решений для нереляционных БД
